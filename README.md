# About this Repo
Used for self learning sequence modeling, ranging from different types of attention to many more methods like ssm
You will find implementations of many papers as well as study notes regarding them

# Implementation of different attention types

## Upcoming implementations
core/cross_attention
core/self_guided_attention
core/multiquery_attention
core/talking_head_attention
core/RoPe_attention
efficient/flash_attention
efficient/cost_former
efficient/Linear_attention
efficient/Big_bird

